{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069082a-e40d-43e5-bbe0-bd71a19ce873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer(return_X_y=False, as_frame=True)\n",
    "#print(data.feature_names)\n",
    "df = data.frame\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    " 'mean smoothness', 'mean compactness', 'mean concavity',\n",
    " 'mean concave points', 'mean symmetry', 'mean fractal dimension']\n",
    "X = df[features]\n",
    "y = df.target\n",
    "\n",
    "# test 1, only features and no scaling\n",
    "\n",
    "# split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=28)\n",
    "\n",
    "# build the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "#print(y_prob)\n",
    "\n",
    "# set a custom threshold\n",
    "threshold = 0.4\n",
    "y_pred_custom_thresh = (y_prob >= threshold).astype(int)\n",
    "# print(y_pred)\n",
    "# print(y_pred_custom_thresh)\n",
    "#print(list(y_test))\n",
    "\n",
    "cmatrix1 = confusion_matrix(y_test,y_pred_custom_thresh)\n",
    "print(\"Confusion matrix 1:\")\n",
    "print(cmatrix1)\n",
    "print('accuracy score:', + (accuracy_score(y_test,y_pred_custom_thresh)))\n",
    "print('f1 score:', + (f1_score(y_test,y_pred_custom_thresh)))\n",
    "print()\n",
    "\n",
    "# now try to normalize the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y,test_size=0.2, random_state=28)\n",
    "\n",
    "# build the model with normalized data\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "y_prob2 = model2.predict_proba(X_test2)[:,1]\n",
    "\n",
    "y_pred2_custom_thresh = (y_prob2 >= threshold).astype(int)\n",
    "\n",
    "cmatrix2 = confusion_matrix(y_test2,y_pred2_custom_thresh)\n",
    "print(\"Confusion matrix 2:\")\n",
    "print(cmatrix2)\n",
    "print('accuracy score:', + (accuracy_score(y_test2,y_pred2_custom_thresh)))\n",
    "print('f1 score:', + (f1_score(y_test2,y_pred2_custom_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c55d2-c9c5-4dc8-a309-a9b01caafde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# so apparently I can just treat the errors as features too\n",
    "\n",
    "data = load_breast_cancer(return_X_y=False, as_frame=True)\n",
    "\n",
    "df = data.frame\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.target\n",
    "\n",
    "# test 1, only features and no scaling\n",
    "\n",
    "# split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=28)\n",
    "\n",
    "# build the model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "#print(y_prob)\n",
    "\n",
    "# set a custom threshold\n",
    "threshold = 0.35\n",
    "y_pred_custom_thresh = (y_prob >= threshold).astype(int)\n",
    "# print(y_pred)\n",
    "# print(y_pred_custom_thresh)\n",
    "#print(list(y_test))\n",
    "\n",
    "cmatrix1 = confusion_matrix(y_test,y_pred_custom_thresh)\n",
    "print(\"Confusion matrix 1:\")\n",
    "print(cmatrix1)\n",
    "print('accuracy score:', + (accuracy_score(y_test,y_pred_custom_thresh)))\n",
    "print('f1 score:', + (f1_score(y_test,y_pred_custom_thresh)))\n",
    "print()\n",
    "\n",
    "# now try to normalize the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y,test_size=0.2, random_state=28)\n",
    "\n",
    "# build the model with normalized data\n",
    "model2 = LogisticRegression(max_iter=10000)\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "y_prob2 = model2.predict_proba(X_test2)[:,1]\n",
    "\n",
    "y_pred2_custom_thresh = (y_prob2 >= threshold).astype(int)\n",
    "\n",
    "cmatrix2 = confusion_matrix(y_test2,y_pred2_custom_thresh)\n",
    "print(\"Confusion matrix 2:\")\n",
    "print(cmatrix2)\n",
    "print('accuracy score:', + (accuracy_score(y_test2,y_pred2_custom_thresh)))\n",
    "print('f1 score:', + (f1_score(y_test2,y_pred2_custom_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4afc15-6f08-471a-86a8-318db89cfbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print((25+36)/(25+36+9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686301c5-2af6-4cee-8e24-c24836ddc26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "transactions = pd.read_csv('transactions_modified.csv')\n",
    "print(transactions.head())\n",
    "print(transactions.info())\n",
    "\n",
    "# Summary statistics on amount column\n",
    "transactions['amount'].describe()\n",
    "\n",
    "# Create isPayment field\n",
    "transactions['isPayment'] = 0\n",
    "transactions['isPayment'][transactions['type'].isin(['PAYMENT','DEBIT'])] = 1\n",
    "\n",
    "# Create isMovement field\n",
    "transactions['isMovement'] = 0\n",
    "transactions['isMovement'][transactions['type'].isin(['CASH_OUT', 'TRANSFER'])] = 1\n",
    "\n",
    "# Create accountDiff field\n",
    "transactions['accountDiff'] = abs(transactions['oldbalanceDest'] - transactions['oldbalanceOrg'])\n",
    "\n",
    "# Create features and label variables\n",
    "features = transactions[['amount','isPayment','isMovement','accountDiff']]\n",
    "label = transactions['isFraud']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label, \n",
    "                                                    test_size=0.3,random_state = 30)\n",
    "\n",
    "# Normalize the features variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the training data\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# Score the model on the test data\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# Print the model coefficients\n",
    "print(model.coef_)\n",
    "\n",
    "# # New transaction data\n",
    "# transaction1 = np.array([123456.78, 0.0, 1.0, 54670.1])\n",
    "# transaction2 = np.array([98765.43, 1.0, 0.0, 8524.75])\n",
    "# transaction3 = np.array([543678.31, 1.0, 0.0, 510025.5])\n",
    "\n",
    "# # Create a new transaction\n",
    "# your_transaction = np.array([6472.54, 1.0, 0.0, 55901.23])\n",
    "\n",
    "# # Combine new transactions into a single array\n",
    "# sample_transactions = np.stack((transaction1,transaction2,transaction3,your_transaction))\n",
    "\n",
    "# # Normalize the new transactions\n",
    "# sample_transactions = scaler.transform(sample_transactions)\n",
    "\n",
    "# # Predict fraud on the new transactions\n",
    "# print(model.predict(sample_transactions))\n",
    "\n",
    "# # Show probabilities on the new transactions\n",
    "# print(model.predict_proba(sample_transactions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
