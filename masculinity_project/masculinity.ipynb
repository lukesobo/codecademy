{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aec196-c8af-4e24-8f23-62e151aca5fd",
   "metadata": {},
   "source": [
    "### Setup and Feature Selection\n",
    "Import data, convert text data to numerical data, and select features (can change chosen features in this block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff5ece-5b19-4d07-8a46-7e0c3937e190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('masculinity.csv')\n",
    "\n",
    "# drop columns irrelevant to analysis\n",
    "df = df.iloc[:,3:]\n",
    "\n",
    "features = df.copy()\n",
    "\n",
    "#TODO\n",
    "# what to do with \"no answer\"\n",
    "# convert floats to ints?\n",
    "# nothing obvious to do with q0009\n",
    "# q0010 only applies to employed\n",
    "# q0025 is about children, probably can do something with that\n",
    "# q0026 is sexual orientation\n",
    "\n",
    "#In general, how masculine or “manly” do you feel?\n",
    "features['q0001'] = features['q0001'].map({'Not at all masculine' : 0, 'Not very masculine': 1, 'Somewhat masculine': 2, 'Very masculine': 3})\n",
    "\n",
    "# How important is it to you that others see you as masculine?\n",
    "features['q0002'] = features['q0002'].map({'Not at all important' : 0, 'Not too important': 1, 'Somewhat important': 2, 'Very important': 3})\n",
    "\n",
    "# Where have you gotten your ideas about what it means to be a good man?\n",
    "q4_cols = [col for col in features.columns if col.startswith('q0004')]\n",
    "for col in q4_cols:\n",
    "    features[col] = features[col].apply(lambda x: 0 if x == 'Not selected' else 1)\n",
    "\n",
    "# Do you think that society puts pressure on men in a way that is unhealthy or bad for them?\n",
    "features['q0005'] = features['q0005'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# How often would you do a variety of things? (masculine and not)\n",
    "q7_cols = [col for col in features.columns if col.startswith('q0007')]\n",
    "for col in q7_cols:\n",
    "    features[col] = features[col].map({'Never, and not open to it' : 0, 'Never, but open to it' : 1, 'Rarely' : 2, 'Sometimes' : 3, 'Often' : 4})\n",
    "\n",
    "# Which of the following do you worry about on a daily or near daily basis? (masculine and not)\n",
    "q8_cols = [col for col in features.columns if col.startswith('q0008')]\n",
    "for col in q8_cols:\n",
    "    features[col] = features[col].apply(lambda x: 0 if x == 'Not selected' else 1)\n",
    "\n",
    "# drop all that pertain to work or are shown to subset groups q9 - q16\n",
    "cols_to_drop = ['q0009', 'q0010_0001', 'q0010_0002',\n",
    "       'q0010_0003', 'q0010_0004', 'q0010_0005', 'q0010_0006', 'q0010_0007',\n",
    "       'q0010_0008', 'q0011_0001', 'q0011_0002', 'q0011_0003', 'q0011_0004',\n",
    "       'q0011_0005', 'q0012_0001', 'q0012_0002', 'q0012_0003', 'q0012_0004',\n",
    "       'q0012_0005', 'q0012_0006', 'q0012_0007', 'q0013', 'q0014', 'q0015']\n",
    "\n",
    "features = features.drop(columns=cols_to_drop)\n",
    "\n",
    "#Do you typically feel as though you’re expected to make the first move in romantic relationships?\n",
    "features['q0017'] = features['q0017'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# How often do you try to be the one who pays when on a date?\n",
    "features['q0018'] = features['q0018'].map({'Never' : 0, 'Rarely': 1, 'Sometimes': 2, 'Often': 3, 'Always' : 4})\n",
    "\n",
    "# drop q19, q20, q21\n",
    "cols_to_drop2 = ['q0019_0001', 'q0019_0002', 'q0019_0003',\n",
    "       'q0019_0004', 'q0019_0005', 'q0019_0006', 'q0019_0007', 'q0020_0001',\n",
    "       'q0020_0002', 'q0020_0003', 'q0020_0004', 'q0020_0005', 'q0020_0006',\n",
    "       'q0021_0001', 'q0021_0002', 'q0021_0003', 'q0021_0004']\n",
    "\n",
    "features = features.drop(columns=cols_to_drop2)\n",
    "\n",
    "# Have you changed your behavior in romantic relationships in the wake of #MeToo movement?\n",
    "features['q0022'] = features['q0022'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# demographics\n",
    "\n",
    "# drop q 24, 25, 26, 28\n",
    "cols_to_drop3 = ['q0024', 'q0025_0001', 'q0025_0002', 'q0025_0003', 'q0026', 'q0028']\n",
    "features = features.drop(columns=cols_to_drop3)\n",
    "\n",
    "# What is the last grade of school you completed?\n",
    "features['q0029'] = features['q0029'].map({\"Did not complete high school\" : 0, \"High school or G.E.D.\" : 1, \"Associate's degree\": 2,\n",
    "                               \"Some college\" : 3, \"College graduate\" : 4, \"Post graduate degree\" : 5})\n",
    "features = features.drop(columns='q0029')\n",
    "\n",
    "# drop q30 - what state do you live in?\n",
    "features = features.drop(columns='q0030')\n",
    "\n",
    "features['q0034'] = features['q0034'].map({\"$0-$9,999\" : 0, \"$10,000-$24,999\" : 1, \"$25,000-$49,999\": 2, \"$50,000-$74,999\" : 3,\n",
    "                               \"$75,000-$99,999\" : 4, \"$100,000-$124,999\" : 5, \"$125,000-$149,999\" : 6, \"$150,000-$174,999\" : 7,\n",
    "                               \"$175,000-$199,999\" : 8, \"$200,000+\" : 9 })\n",
    "features = features.drop(columns='q0034')\n",
    "\n",
    "# drop q 35, 36\n",
    "features = features.drop(columns=['q0035', 'q0036'])\n",
    "\n",
    "features['race2'] = features['race2'].apply(lambda x: 1 if x == 'White' else 0)\n",
    "features = features.drop(columns='race2')\n",
    "\n",
    "# drop 'racethn4'\n",
    "features = features.drop(columns='racethn4')\n",
    "\n",
    "features['educ3'] = features['educ3'].map({\"High school or less\" : 0, \"Some college\" : 1, \"College or more\" : 2})\n",
    "features = features.drop(columns='educ3')\n",
    "\n",
    "features['educ4'] = features['educ4'].map({\"High school or less\" : 0, \"Some college\" : 1, \"College or more\" : 2, \"Post graduate degree\" : 3})\n",
    "features = features.drop(columns='educ4')\n",
    "\n",
    "features['age3'] = features['age3'].map({'18 - 34' : 0, '35 - 64' : 1, '65 and up' : 2})\n",
    "features = features.drop(columns='age3')\n",
    "\n",
    "features['kids'] = features['kids'].apply(lambda x: 1 if x == 'Has children' else 0)\n",
    "features = features.drop(columns='kids')\n",
    "\n",
    "# drop 'orientation'\n",
    "features = features.drop(columns='orientation')\n",
    "\n",
    "#what is this weight column? ranges from 0.02 - 8.67?\n",
    "# drop 'weight'\n",
    "features = features.drop(columns='weight')\n",
    "\n",
    "# model 7 - subset to just q7 and q8\n",
    "cols78 = [col for col in features.columns if col.startswith('q0007') or col.startswith('q0008')]\n",
    "features = features[cols78]\n",
    "\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e52940-5a66-40ea-a254-dae7f955b61b",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c48d1a-3258-49b1-830e-795b1f5486b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['q0001', 'q0002']\n",
    "\n",
    "subset = features[cols]\n",
    "\n",
    "subset = subset.dropna()\n",
    "\n",
    "print(pd.crosstab(subset[cols[0]], subset[cols[1]]))\n",
    "\n",
    "plt.scatter(subset[cols[0]], subset[cols[1]], alpha = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5308f9-d48f-4d11-a593-fb89c2cd8f5a",
   "metadata": {},
   "source": [
    "### Modeing\n",
    "\n",
    "Going to use 2 clusters in each model: maybe clusters will group by \"traditionally masculine\" and \"not traditionally masculine\" group. maybe.\n",
    "\n",
    "Goal: Start with a model that includes the most features, then subset to less and less features. Analyze results and groupings of each.\n",
    "\n",
    "Shortcomings (less as model data gets smaller): probably too many features, some features may not even be relevant, many removed rows from nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c970e1-c11e-4c4c-a04c-e41dfd178e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop all rows that are na, convert to ints, 2 clusters\n",
    "\n",
    "def kMeansLabelsPCA(features_df):\n",
    "    a = features_df.dropna()\n",
    "    a = a.astype(int)\n",
    "    scaler = StandardScaler()\n",
    "    a_scaled = scaler.fit_transform(a)\n",
    "    model = KMeans(init='k-means++', n_clusters=2, random_state=49)\n",
    "    labels = model.fit_predict(a_scaled)\n",
    "    #print(model.cluster_centers_)\n",
    "    labeled_points = pd.DataFrame(labels, index=a.index, columns=['label'])\n",
    "    \n",
    "    # PCA to determine which features contribute most to variance\n",
    "    pca = PCA()\n",
    "    pca.fit(a_scaled)\n",
    "    \n",
    "    feature_importance = pd.DataFrame(pca.components_, columns=features.columns, index=[f'PC{i+1}' for i in range(len(features.columns))])\n",
    "    \n",
    "    # focus on first principal component\n",
    "    pc1_contributions = feature_importance.loc['PC1']\n",
    "    important_features_pc1 = pc1_contributions.abs().sort_values(ascending=False)\n",
    "    \n",
    "    return labeled_points, important_features_pc1\n",
    "\n",
    "labels, feature_importance = kMeansLabelsPCA(features)\n",
    "results = df.join(labels, how='inner')\n",
    "print(len(results))\n",
    "\n",
    "results.to_csv('model7.csv', index=False)\n",
    "\n",
    "# Print feature importance for PC1\n",
    "print(\"PC1 Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# further analysis section based on pca results\n",
    "results1 = results1[['q0008_0012', 'q0007_0011', 'q0008_0004', 'label']]\n",
    "\n",
    "columns_to_analyze = results1.columns[:-1]\n",
    "\n",
    "for col in columns_to_analyze:\n",
    "    counts = pd.crosstab(results1[col], results1['label'])\n",
    "    print(f\"Counts for {col}:\\n{counts}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bdeef7-0044-428a-b921-06b61b9111b5",
   "metadata": {},
   "source": [
    "### Results Notes:\n",
    "Model 1 (most features, see first cell) - q8 and q7 most important by PCA.. appears to be anxious lonely people vs not.\n",
    "\n",
    "Model 2 (model 1 minus weight) - same as model 1. anxious lonely men vs not. one sub q8 response change. this is sad.\n",
    "\n",
    "Model 3 (drop redundant education col) - nearly identical to model 3, reducing education redundancy didn't change much.\n",
    "\n",
    "Model 4 (only questions, cols starting with q) - same as models 2 and 3. 'q0008_0012', 'q0007_0011', 'q0008_0004' top 3 by PCA\n",
    "\n",
    "Model 5 (only edu demographic, only survey responses thru q29) - same as models 2, 3 and 4. 'q0008_0012', 'q0007_0011', 'q0008_0004' top 3 by PCA\n",
    "\n",
    "Model 6 (no demographics, only survey responses thru q22) - same as models 2, 3 and 4. 'q0008_0012', 'q0007_0011', 'q0008_0004' top 3 by PCA\n",
    "\n",
    "Model 7 - seems clear that q7 and q8 make the biggest differece. Subset to just those qs. 'q0008_0012', 'q0007_0011', 'q0008_0004' top 3 by PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2385a-2423-4e58-a43d-caf7ec589206",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Using K means clustering, the majority of variability between the two clusters of men who answered this survey was explained by the following:\n",
    "\n",
    "Cluster 1: \n",
    "- Were not worried about any of the common insecurities in question 8 (q0008_0012)\n",
    "- Were not worried about their physique (q0008_0004)\n",
    "- Were not seeing a therapist and were less open to the idea (q0007_0011)\n",
    "\n",
    "Cluster 2:\n",
    "- Worried about one or more of the insecurities listed in question 8 (q0008_0012)\n",
    "- Were more likely to be concerned about their physique (q0008_0004)\n",
    "- Were more likely to have seen or are actively seeing a therapist (q0007_0011)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
